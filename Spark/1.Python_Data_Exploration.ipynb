{"cells":[{"cell_type":"markdown","source":["## Exploring Data with DataFrames and Spark SQL"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.master(\"yarn\").appName(\"GLIM_PGPBABI\").enableHiveSupport().getOrCreate()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["### Read data from a Hive Table"],"metadata":{}},{"cell_type":"code","source":["student_df = spark.sql(\"SELECT * FROM studentmaster\")"],"metadata":{"collapsed":false},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["### Use DataFrame Methods\nSpark DataFrames provide functions that you can use to extract and manipulate data. For example, you can use the **select** function to return a new DataFrame containing columns selected from an existing DataFrame."],"metadata":{}},{"cell_type":"code","source":["student_df.select(\"School\", \"Reason\").show(n=10, truncate=False)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":6},{"cell_type":"code","source":["student_df\\\n.filter(student_df['G3'] >=15)\\\n.count()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["### Combine Operations\nIn this case, you will use the **filter** function followed by the **select** and **describe** functions to return the summary statistics for the three exam scores for one of the schools"],"metadata":{}},{"cell_type":"code","source":["summary_stats_by_school = student_df \\\n                                  .filter(student_df['School'] == 1) \\\n                                  .select('G1','G2','G3') \\\n                                  .describe()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":9},{"cell_type":"code","source":["summary_stats_by_school.show()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["### Count the Rows in a DataFrame\nNow that you're familiar with working with DataFrames, a key task when building predictive solutions is to explore the data, determing statistics that will help you understand the data before building predictive models. For example, how many rows of flight data do you actually have?"],"metadata":{}},{"cell_type":"code","source":["student_df.count()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["### Determine Summary Statistics\nPredictive modeling is based on statistics and probability, so you will often start by looking at summary statistics. The **describe** function returns a DataFrame containing the **count**, **mean**, **standard deviation**, **minimum**, and **maximum** values for each numeric column."],"metadata":{}},{"cell_type":"code","source":["student_df.select('G1','G2','G3').describe().show()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["### Determine the Presence of Duplicates\nThe data you have to work with won't always be perfect - often you'll want to *clean* the data; for example to detect and remove duplicates that might affect your model. You can use the **dropDuplicates** function to create a new DataFrame with the duplicates removed, enabling you to determine how many rows are duplicates of other rows."],"metadata":{}},{"cell_type":"code","source":["student_df.count() - student_df.dropDuplicates().count()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["### Identify Missing Values\nAs well as determing if duplicates exist in your data, you should detect missing values, and either remove rows containing missing data or replace the missing values with a suitable relacement. The **dropna** function creates a DataFrame with any rows containing missing data removed - you can specify a subset of columns, and whether the row should be removed in *any* or *all* values are missing. You can then use this new DataFrame to determine how many rows contain missing values."],"metadata":{}},{"cell_type":"code","source":["student_df.count() - student_df.dropDuplicates().dropna(how=\"any\", subset=['G1','G2','G3']).count()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["### Clean the Data\nIf there are duplicates and missing values, you can clean the data by removing the duplicates and replacing the missing values. The **fillna** function replaces missing values with a specified replacement value. In this case, you'll remove all duplicate rows and replace missing **G1**, **G2** and **G3** values with **0**."],"metadata":{}},{"cell_type":"code","source":["'''data=student_df.dropDuplicates().fillna(value=0, subset=['G1','G2','G3'])\ndata.count()'''"],"metadata":{"collapsed":true},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["### Explore Relationships in the Data\nPredictive modeling is largely based on statistical relationships between fields in the data. To design a good model, you need to understand how the data points relate to one another and identify any apparent correlation. The **corr** function calculates a correlation value between -1 and 1, indicating the strength of correlation between two fields. A strong positive correlation (near 1) indicates that high values for one column are often found with high values for the other, which a string negative correlation (near -1) indicates that *low* values for one column are often found with *high* values for the other. A correlation near 0 indicates little apparent relationship between the fields."],"metadata":{}},{"cell_type":"code","source":["student_df.corr(\"G2\", \"G3\")"],"metadata":{"collapsed":false,"scrolled":true},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["### Use Spark SQL\nIn addition to using the DataFrame API directly to query data, you can persist DataFrames as table and use Spark SQL to query them using the SQL language. SQL is often more intuitive to use when querying tabular data structures."],"metadata":{}},{"cell_type":"code","source":["student_df.createOrReplaceTempView(\"student_view\")"],"metadata":{"collapsed":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":["spark.sql(\"SELECT School, COUNT(G3) AS NumStudents, AVG(G3) AS AvgScore FROM student_view GROUP BY School ORDER BY School\").show()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["### Use the Inline SQL *Magic*\nJupyter Notebooks support *magics*, which enable you to include inline code and functionality. For example, the **%%sql** magic enables you to write SQL queries and visualize the results directly in the notebook.\n\nRun the following query, and view the table of results that is returned."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT G2, G3 FROM student_view"],"metadata":{"collapsed":false},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["Change the **Table** visualization of results above to a **Scatter** visualization to see the relationship between the **G2** and **G3** values more clearly (use the **-** function to plot the actual values) - visualizations like this make it easier to show relationships as apparent *structure* in the data. For example, the positive correlation between **G2** and **G3** seems to be a linear relationsip, creaing a diagonal line of plotted points."],"metadata":{}},{"cell_type":"markdown","source":["### Query Multiple Tables\nYou can create and query multiple temporary tables. Run the cells below to create a temporary table from the **airports** DataFrame, and then use an inline query to query it together with the flights data."],"metadata":{}},{"cell_type":"code","source":["school_df = spark.sql(\"SELECT * FROM school\")\nreason_df = spark.sql(\"SELECT * FROM reason\")"],"metadata":{"collapsed":false},"outputs":[],"execution_count":30},{"cell_type":"code","source":["school_df.createOrReplaceTempView(\"school_view\")\nreason_df.createOrReplaceTempView(\"reason_view\")"],"metadata":{"collapsed":true},"outputs":[],"execution_count":31},{"cell_type":"code","source":["%sql\nSELECT b.Category AS JoiningReason, AVG(a.G3) AS AvgScore\nFROM student_view AS a JOIN reason_view AS b\nON a.Reason = b.LabelID\nGROUP BY b.Category\nORDER BY AVG(a.G3) DESC"],"metadata":{"collapsed":false},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["As you saw previously, it can sometimes be useful to visualize the results of a query. Change the visualization above to a **Bar** chart, using the **-** function, to see the average scores achieved by students based on the reasons for joining."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT b.Category AS SchoolName, c.Category AS JoiningReason, AVG(a.G3) AS AvgScore\nFROM student_view AS a JOIN school_view AS b\nON a.School = b.LabelID JOIN reason_view AS c\nON a.Reason = c.LabelID\nGROUP BY b.Category, c.Category\nORDER BY b.Category, AVG(a.G3) DESC"],"metadata":{"collapsed":false},"outputs":[],"execution_count":34}],"metadata":{"language_info":{"codemirror_mode":{"name":"python","version":2.0},"mimetype":"text/x-python","name":"pyspark","pygments_lexer":"python2"},"name":"1.Python_Data_Exploration","notebookId":2854966953941114,"kernelspec":{"display_name":"PySpark","language":"","name":"pysparkkernel"},"anaconda-cloud":{},"widgets":{"state":{"33997d571fdb43ebb5f1b28eb846ff91":{"views":[{"cell_index":26.0}]},"66e9907a503f4e38ae34bb37375d3de8":{"views":[{"cell_index":33.0}]},"236e776d3e1b45d6b2522d290b0c52bf":{"views":[{"cell_index":31.0}]},"a4b26b309a8c4d568f7f2b60b53c5bf7":{"views":[{"cell_index":33.0}]},"adaa4355f7b241ba9c3726bca8cc720b":{"views":[{"cell_index":31.0}]},"58ed130133694cf89e4518d1c8b45fd9":{"views":[{"cell_index":31.0}]},"fa4c21737d374f61ad900f3343a7b9f3":{"views":[{"cell_index":31.0}]},"dc5ae922d6ce4176ad55ac5a49577255":{"views":[{"cell_index":33.0}]},"2c12ade2863845b683ab7a70727672b2":{"views":[{"cell_index":31.0}]},"4a2635991de84d8dbb6bf3b21f9d1fc7":{"views":[{"cell_index":26.0}]},"aad2283a7fba45958018acf26c6cde92":{"views":[{"cell_index":31.0}]},"c81eba46bcdf4063ad34b7cd21f46443":{"views":[{"cell_index":31.0}]}},"version":"1.2.0"}},"nbformat":4,"nbformat_minor":0}
